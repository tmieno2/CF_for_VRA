---
title: "Causal Forest Approach for Site-specific Input Management via On-farm Precision Experimentation"
author: Shunkei Kakimoto^[Corresponding author, Department of Agricultural Economics, University of Nebraska-Lincoln 102 Filley Hall 1625 Arbor Drive Lincoln, NE 68583, USA, E-mail address; skakimoto3@hunskers.unl.edu], Taro Mieno^[Department of Agricultural Economics, University of Nebraska-Lincoln, Lincoln, NE 68583, USA], Takashi S. T. Tanaka^[Artificial Intelligence Advanced Research Center, Faculty of Applied Biological Sciences, Gifu University, Gifu 501-1193, Japan], and David S. Bullock^[Department of Agricultural and Consumer Economics, University of Illinois, Urbana, IL 61801, USA]
output:
  bookdown::word_document2:
    fig_caption: yes
    number_sections: yes
    global_numbering: true
    # reference_docx: word_template.docx
    reference_docx: word_template_format.docx
    # pandoc_args: ["-Fpandoc-crossref"]
bibliography: ML_VRA.bib
csl: computers-and-electronics-in-agriculture.csl
eqnPrefix: 
      - "Eq"
abstract: "Estimating site-specific crop yield response to changes to input (e.g., seed, fertilizer) management is a critical step in making economically optimal site-specific input management recommendations. Past studies have attempted to estimate yield response functions using various Machine Learning (ML) methods, including the Random Forest (RF), Boosted Random Forest (BRF), and Convolutional Neural Network (CNN) methods. This study proposes use of the Causal Forest (CF) model, which is one of the emerging ML methods that comprise \"Causal Machine Learning.\" Unlike previous yield-prediction-oriented ML methods, CF focuses strictly on estimating heterogeneous treatment effects (changes in yields that result from changes in input application rates) of inputs. We report results of using Monte Carlo simulations assuming various production scenarios to test the effectiveness of CF in estimating site-specific economically optimal nitrogen rates (EONRs), comparing CF with the yield-prediction-oriented ML methods RF, BRF, and CNN. CF's estimations of site-specific EONRs were superior under all scenarios considered. We also show that the quality of a model's yield predictions provides little if any information about the quality of its EONR predictions."  
---

```{r echo = F, include = FALSE, cache = F}
library(knitr)
library(here)
here::i_am("GitControlled/Writing/manuscript_cea.rmd")
# opts_knit$set(root.dir = here())

options(htmltools.dir.version = FALSE)
options(knitr.duplicate.label = "allow")

opts_chunk$set(
  fig.align = "center",
  fig.retina = 5,
  warning = F,
  message = F,
  cache = F,
  echo = F
)
```

```{r, cache = FALSE}
# === packages ===#
library(tidyverse)
library(data.table)
library(sf)
library(png)
library(RColorBrewer)
library(patchwork)
library(plotly)
library(magrittr)
library(ggplot2)
library(viridis)
library(tmap)
library(ggthemes)
library(mgcv)
library(ggpubr)
library(flextable)
library(officer)
library(officedown)
library(modelsummary)
library(raster)
library(bookdown)
library(png)
library(grid)
library(causalTree)
library(rpart)
library(rattle)
```
```{r, include = F, cache = F}
knit_child(here("GitControlled/Codes/PrepareResults.Rmd"), quiet = TRUE)
```

# Keywords: {-}

site-specific input management, nitrogen rate, on-farm precision experimentation, machine learning, causal forest, economically optimal input rates

# Introduction

Information about crop yield response input management is critical for the identification of site-specific economically optimal input rates (EOIRs) [@bullock1998does], and the difficulty in estimating site-specific yield response functions accurately within a field is the primary explanation of the persistent relatively low the adoption rate of variable rate crop input application technology [@lowenberg2019setting]. Historically, site-specific yield response functions have been estimated using the data generated from strip trials conducted on only parts of fields [@anselin2004spatial; @bullock2002adding; @hurley2004estimating; @makowski2001statistical; @mamo2003spatial; @Miao2006; @puntel2019development; @ruffo2006site; @scharf2002corn; @scharf2005field].
But recently whole-field on-farm precision experimentation (OFPE) [@bullock2019] has allowed implementation of improved statistical experimental designs (e.g., Latin Square, Randomized Block) on entire fields [@laurent_kyveryga_makowski_miguez_2019; @licht_witt_2019]. Data generated from whole-field OFPEs typically have greater local variation in experimental input application rates and soil/field characteristics than do strip trial designs, which has improved the statistical identification of heterogeneous impacts of input management changes on yields. The resultant availability of more spatially detailed experiment data has encouraged a resurgence of interest in estimating site-specific yield response functions. For example, Barbosa et al. [-@barbosa2020risk; -@barbosa2020modeling], @krause2020random and @Gardner21 used OFPE data to estimate site-specific yield response functions and economically optimal site-specific N fertilizer and/or seed rates. These recent studies used machine learning (ML) methods extensively in place of more traditional parametric modeling approaches. Barbosa et al. [-@barbosa2020risk; -@barbosa2020modeling] took a Convolutional Neural Network approach, @krause2020random used Random Forest-based approaches, and @Gardner21 used the shape-constrained generalized additive model. 
But this trend of applying ML methods may raise concerns. Historically, agronomists have worked meticulously to develop clever experimental designs to identify causes of yield response to input management. But the aforementioned recent applications of ML methodologies pay little attention to identifying such causes, but instead attempt to validate their models by estimating yield prediction accuracy. But the ultimate goal of OFPE is the accurate prediction of EOIRs, not yields. These are distinct objectives, and achievement of one need not imply the other.

The lack of and need for causal interpretation of the results of ML research applications have been increasingly recognized, in particular in economics and medicine [@athey2017beyond; @athey2018impact; @Athey2019a; @moraffah2020causal; @Storm2020; @arti2020research; @scholkopf2021toward], and causal machine learning (CML) methods were recently developed in response. Unlike traditional prediction-oriented ML methods, CML focuses on identifying causal impacts of an event (in our context, of an increase or decrease in the input application rate). The growing academic literature applying CML methods includes @richens2020improving, whose medical research pointed out that the inability of the traditional ML methods to identify cause-and-effect relationships between disease and patients' characteristics could lead to misdiagnoses, and showed that CML-based diagnoses could improve the accuracy of diagnostic prediction. In addition, @carbo2020machine used a CML to identify characteristics causing bank customers to adopt online banking services, and @bozorgi2020process applied CML to study mining processes.

We use the Causal Forest (CF) approach developed by @athey2016recursive and @Wager2018a to examine the accuracy of methods that estimate site-specific economically optimal N fertilizer rates (EONRs). We compare the EONR prediction performances of our CF-based approach to the widely used ML methods Random Forest (RF), Boosted Random Forest (BRF), and Convolutional Neural Network (CNN), and we examine the relation between yield prediction performance and EONR prediction performance, which allows us to study whether model selection should be based on yield prediction accuracy when the ultimate goal is EOIR identification. We use Monte Carlo simulations in which we synthetically generate yield and soil/field characteristics datasets to create stylized "field." Because real-world "true" EOIRs are unobservable, real-world data cannot be used to test the accuracy of statistical methods estimating EOIRs. This important difference contrasts starkly with yield prediction, since actual yields can be ground-truthed.

# Predicting Yield vs. Predicting Changes in Yield in Response to Changes in Input Management

In the following, we describe the fundamental information necessary to identify EOIR in general: the site-specific treatment effect of input application on yield. We then discuss the causal forest method in detail, show how it is particularly suited to the gathering of this fundamental information, and contrast it to more traditional prediction-oriented ML methods, such as RF, BRF, and CNN.

## EOIR Estimation and Treatment Effects

Let $p$ be the price that a producer receives for a unit of a crop, $w$ be the per-unit price paid for a unit of an input, $OC$ represent other costs of production, and $y=f(I, \mathbf{c})$ describe the relationship between crop yield, the input application rate $I$ and a vector of field characteristics variables $\mathbf{c}$. A simple model of producer behavior assumes that the producer chooses a level of $I$ to maximize profits (revenues minus costs):

\begin{equation}
\max_{I} \quad pf(I, \mathbf{c}) - wI -OC. (\#eq:eqn1)
\end{equation}

Elementary calculus shows that the necessary condition for maximization is, that $\partial f(I, \mathbf{c})/\partial I - w =0$, which implicitly defines the economically optimal input application rate as a function of prices and soil/field characteristics, and may be arranged as \@ref(eq:eqn2):

\begin{equation}
\frac{\partial f(I^{*}(p,w,\mathbf{c}), \mathbf{c})}{\partial I} \equiv \frac{w}{p}. (\#eq:eqn2)
\end{equation}

Identity \@ref(eq:eqn2) states that the necessary elements of the information needed for profit maximization are the input price, the output price, and the partial derivative of the yield function with respect to the input. While knowledge of the yield function $f(I, \mathbf{c})$ in Eq. \@ref(eq:eqn1) is sufficient to solve the maximization problem above (since its derivative can be calculated), identity \@ref(eq:eqn2) shows that it is not a necessary condition; rather, knowing the "change" in yield in response to a change in input rate is. 

Recent studies using ML methods to estimate the effectiveness of various agricultural input management strategies first estimate yield function, $f(I, \mathbf{c})$ (e.g., Barbosa et al. [-@barbosa2020risk; -@barbosa2020modeling]; @krause2020random; and @Gardner21) and then derive changes in yield associated with changes in the input rate to estimate site-specific input application recommendations. On the other hand, Causal Forest is designed specifically to estimate a discrete version of Eq. \@ref(eq:eqn2) directly, examining the discrete changes in yield that result from discrete *changes* in the input application rate $I$, bypassing the estimation of $f(I, \mathbf{c})$. It may be suspected that CF will outperform other ML methods that identify EOIR indirectly through yield prediction. Below we offer details about how CF works and may perform better in predicting EOIR than other prediction-oriented ML methods previously reported.

## Causal Forest

CF was developed specifically for identifying heterogeneous treatment effects [@athey2016recursive; @Wager2018a]. Like RF, CF works by building an ensemble of trees, called *causal trees* (CTs), by recursively partitioning covariate space into two leaves, where each leaf estimates conditional average treatment effects as the mean differences between the dependent variable (here yield) of the treated and control observations that belong to the leaf. (See Appendix A for an example.) 

While both RF and CF build trees by recursively partitioning samples, they differ critically in their criteria for splitting. In RF, the sample is split to minimize the mean squared error (MSE) of yield prediction in building trees. Unfortunately, the MSE of treatment effect predictions is not useful for building a CT since the true treatment effects are never observable. However, @athey2016recursive showed that minimizing the expected MSE of the treatment effect is equivalent to maximizing the variance of treatment effects across the resulting two leaves and minimizing the within-leaf variance. Consequently, by splitting samples in a way that maximizes the variance of treatment effects across the resulting two leaves, CF overcomes the fundamental problem created by the unobservability of true treatment effects. CF requires that the tree-building process be "honest" for treatment effects estimation to be unbiased. Honest tree-building first randomly splits the training data samples in two, then uses one of the subsamples to determine how to split the tree, and the other to estimate the treatment effects [@athey2016recursive; @Wager2018a]. This honest subsampling technique avoids overestimation of the heterogeneity of estimated treatment effects. Since CF splits samples to maximize the heterogeneity of estimated treatment effects, using the same sample for both the sample splitting and treatment effect calculations renders itself sensitive to noise or outliers, allowing high noise levels to exaggerate the treatment effects. 

## CF vs. Prediction-oriented ML methods

Whether the indirect (yield-prediction-first) or direct approach is used can lead to meaningful statistical differences when it comes to EOIR estimation. The conventional prediction-oriented ML methods are designed to predict yield $y_i(I,\mathbf{c})$ well, but not necessarily treatment effects. Since the loss function used in prediction-oriented ML uses (typically squared) residuals in yield prediction, prediction-oriented ML is naturally optimized for predicting the "level" of yield instead of identifying this causal impact of the input on yield. CF, on the other hand, is designed specifically to estimate this causal impact. Indeed, Wager and Atheyâ€™s[-@Wager2018a] Monte Carlo simulations showed that the estimates of heterogeneous treatment effects provided by CF were more accurate than those provided by RF. However, their simulations' underlying data-generating process was extremely simple, with the treatment effect influenced by only a single variable. CF has not been tested for more complicated data generating processes, such as those represented by yield response functions in which the treatment effect of an input can be affected by multiple variables in a non-linear fashion. Moreover, CF has never been compared to more advanced ML methods such as BRF and CNN that are considered to have prediction capabilities greater than RF's. The study reported here builds on @Wager2018a to compare CF to these prediction-oriented ML methods (not just RF, but also BRF and CNN) in more realistic agronomic experiment settings.


# Materials and Methods

Estimates of site-specific EONRs were conducted using Monte Carlo simulations of nitrogen fertilizer application experiments for corn production. The simulations' first step generated one thousand synthetic fields that "resembled" an actual field. Field characteristics and yield were simulated assuming the Mitscherlich-Baule (MB) yield response function. We used the RF, BRF, and CNN ML methods to estimate yield response functions, and we used the CF method to estimate treatment effects. For each method, we estimated site-specific EONRs using the training dataset, and checked the statistical performance of the predicted site-specific EONR using the validation dataset. Detailed descriptions of these steps are provided below. The R and Python codes that implement the simulation analyses are publicly accessible as a Mendeley dataset [@Kakimoto2022codes], or as a Github repository at https://github.com/Shunkei3/VRA_with_CF.git.


## Data Generation

### Simulated Experimental Fields
<!-- experimental field: area: 51ha, plot: 384, subplot:1536, cell:55296   -->

The simulated field was created based on an actual 51-ha Illinois field on which the Data-Intensive Farm Management (DIFM) project [@bullock2019] has run multiple OFPEs. Figure \@ref(fig:field-map) illustrates that simulated trials consisted of 384 18.3 m $\times$ 73.2 m "plots," each of which was assigned an N fertilizer application rate. Each plot was made up of four (4-rows $\times$ 1-column) 18.3 m $\times$ 18.3 m "subplots," which were unit of analysis used in subsequent statistical analysis. Each subplot contained a 6-row $\times$ 6-column grid of thirty-six 3.05 m $\times$ 3.05 m "cells." All field characteristics and yield data were generated at the cell level.

```{r field-map, fig.width=8, fig.height=8, fig.cap = "Partitioning of field into plots, subplots and cells"}
field_structure
```

### Cell-specific Yield Functions and True Economically Optimal N Rates

We modeled the yield response function as having the Mitscherlich-Baule functional form, which is flexible in its shape, allows for the existence of a yield plateau, and has been shown to be a plausible specification for N fertilization models for corn [@frank1990; @llewelyn1997; @paris1992].

Let $i \in \{1,2,\dots,1536\}$ index a simulated field's subplots and $j \in \{1,2,\dots,36\}$ index cells within subplots. Let $N_{i}$ be the N fertilization rate on subplot $i$. Eq. \@ref(eq:eqn3) shows the yield level on cell $j$ in subplot $i$:

\begin{equation}
f(N_{i}: \alpha_{i,j}, \beta_{i,j}, ymax_{i,j}) = ymax_{i,j}(1-exp(\alpha_{i,j} + \beta_{i,j} \cdot N_{i})) + \varepsilon_{i,j}. (\#eq:eqn3)
\end{equation}

The first term on the right-hand side of Eq. \@ref(eq:eqn3) is the deterministic yield component. The variable $N$ represents the nitrogen fertilizer application rate (kg/ha) which the trial designs varied by plot. Also in Eq. \@ref(eq:eqn3), $\alpha$, $\beta$, and $ymax$ are spatially varying parameters that govern how yield level is determined in conjunction with the applied N rate. They reflect local cell-level production conditions, such as soil characteristics and topography. For example, $\alpha$, which represents what the yield would be when no nitrogen is applied in conjunction with $ymax$, may reflect soil organic matter and residual nitrogen from previous year's production. $ymax$, which determines the maximum yield attainable, may include other micro nutrients like phosphorus and soil depth. $\beta$ can be interpreted as reflecting how efficiently the crop uses N to create grain mass, and might depend on soil properties that affect the availability of applied N fertilizer to the crop, say due to N immobilization, leaching, denitrification, and volatilization [@johnson2005nitrogen; @alva2006nitrogen]. Figure \@ref(fig:vis-MB-curve) presents examples of site-specific yield response functions for five sites.  

```{r vis-MB-curve, fig.cap = "Examples of site-specific Mitscherlich-Baule yield response curves"}
vis_MB_curve
```

The yield error term $\varepsilon$ represents the impact of the composite of all the unobserved factors that affect crop yield that are not accounted for by $\alpha$, $\beta$, $ymax$ and $N$. Each cell $(i,j)$'s "true" optimal N application rate, denoted $N^{opt}_{i,j}$, was calculated by solving a profit maximization problem by cell assuming that the prices of corn and N fertilizer were $\$0.138/kg$ and $\$1.323/kg$ in all simulations. See Appendix C.1 for further details on how the parameters were generated and sample maps of the parameters and true economically optimal N rates.

### Trial Design and Yield Data Generation for Modeling

In each simulation round, five field-trial N rates were determined based on the range of the round's cell-specific EONRs. 
Let $Q_q$ ($q \in [0,1]$) denote the $100 \times q$ percentile of the round's cell-specific EONRs. Then, the five trial design rates were $N_1 = Q_{0.05} - 20$, $N_5 = Q_{0.95} + 20$, $N_2 = N_1 + 0.25(N_5 - N_1)$, $N_3 = N_1 + 0.50(N_5 - N_1)$, $N_4 = N_1 + 0.75(N_5 - N_1)$. 
In each round, a Latin square design was followed to assign to each plot one of the five N rates so established. The left-most panel of Figure \@ref(fig:fig-nExp-yield) shows an example of a trial design. The N rate was orthogonal to the error term in every simulation's trial design. This is important because correlation between N and the error term would introduce bias in the estimation of the impact of N on yield for all ML methods. Since the treatment effect at each leaf is obtained simply by taking the difference of the average value of the dependent variable between the control and treated group within the leaf, to estimate the treatment effect consistently CF requires the exogeneity of the treatment conditional on the independent variables. Note that violation of this condition would lead to biased estimation using the CF and the other ML methods. 

A cell-level dataset for the whole field, $\{(y_{i,j}, N^{opt}_{i,j}, N_{i,j}, \mathbf{c}_{i,j}): i \in \{1,2,\dots,1536\}, j \in \{1,2,\dots,36\}\}$ was generated by plugging in the parameter values, the error term, and the assigned nitrogen rates into Eq. \@ref(eq:eqn3). The cell-level data were then aggregated up to the subplot level by taking the mean of the cell-level values inside each subplot, which were the unit of observation of the generated dataset:

\begin{equation}
\{(y_{i}, N^{opt}_{i}, N_{i}) = \frac{1}{36}\sum_{j=1}^{36} (y_{i,j}, N^{opt}_{i,j}, N_{i,j}): i \in \{1,2,\dots,1536\}\}. (\#eq:eqn4)
\end{equation}

The right panel of Figure \@ref(fig:fig-nExp-yield) shows an example of observed yield data. Note that data generation at the cell level was conducted to reflect the real-world spatial heterogeneity in soil/field characteristics within the subplot level. But data aggregation to the subplot level was conducted because the large sizes of harvesters make it impossible to monitor yields accurately at smaller scales.

```{r fig-nExp-yield, fig.width=7, fig.height=6, fig.cap = "An example of experimental design of N and generated yield at the subplot resolution"}
field_Ndesign | vis_yield_subplot
```

## Modeling Scenarios

To evaluate the performances of RF, BRF, CNN and CF, we examined four modeling scenarios, each defined by a dataset assumed to be available to the researcher. The first modeling scenario, denoted "aby" assumed that the researcher has a dataset of the actual values of yield function parameters $\alpha_{i}$, $\beta_{i}$, and $ymax_{i}$ for every subplot $i$ and uses them as covariates in the ML models. This scenario represents an ideal situation for the researcher in which all the relevant variables are observed, but the true functional form of the heterogeneous yield response functions are not known. More realistic scenarios could be compared with this ideal scenario.

In subsequent modeling scenarios, we made the simulated experimental data more realistic by varying the degree to which the researcher understood what the needed covariates' values were those in the dataset. In the second scenario, denoted "abytt," we introduced additional variables $\theta^1$ and $\theta^2$, and the researcher's dataset contained values of $\alpha_{i}$, $\beta_{i}$, $ymax_{i}$, $\theta^1_{i}$ and $\theta^2_{i}$ for all subplots $i=1,\dots,1536$. $\theta^1$ and $\theta^2$ had no effect on yield, but were spatially correlated with $\beta_{i}$. This scenario was meant to reflect the lack of scientific consensus about which variables explain heterogeneous yield response to N, making it likely that the researcher would include irrelevant variables like $\theta^1$ and $\theta^2$ in real-world data analysis. 

In the third scenario, denoted "aabbyy," the researcher's dataset did not contain values of $\alpha_{i}$, $\beta_{i}$, or $ymax_{i}$. Rather, it contained subplot-level values of permutations of $\alpha$, $\beta$, and $ymax$. Each of the three parameters was split into two parts in a spatially correlated manner, and six new covariates were created. (See Appendix C.2 for the details about this parameter-splitting process.) These were $\alpha^{1}_{i}$, $\alpha^{2}_{i}$, $\beta^{1}_{i}$, $\beta^{2}_{i}$, $ymax^{1}_{i}$, and $ymax^{2}_{i}$. The two split variables were spatially correlated to reflect that many of the soil/field characteristics used to analyze OFPE data are spatially correlated. The values of $\alpha_{i}$, $\beta_{i}$ and $ymax_{i}$ did not indicate specific soil or field characteristics, but were functions of such. In reality, scientists cannot directly observe variables that can accurately predict yield plateau level, soil N content and N uptake efficiency. Rather, they use multiple observed soil/field characteristics to explain such phenological phenomena. For example, instead of using $ymax_{i}$ directly, some topographical land features and soil properties such as elevation and soil sand content could be used as yield-limiting factors [@jiang2004effect; @kravchenko2000correlation]. In reality, scientists may include more than three variables as covariates. This scenario should reduce the accuracy of EONR modeling for all the models compared to the ideal case. 

The fourth scenario, denoted "aabbyytt," had the same components as aabbyy, but also included the $\theta_1$ and $\theta_2$ covariates.

## Training Models and Estimating Site-specific EONRs

### Training and Estimation of Site-specific EONRs by RF, BRF, and CNN

The RF, BRF, and CNN methods all followed the same conceptual steps to estimate site-specific EONRs: 1) estimate the yield production functions and 2) use those estimated functions to calculate site-specific EONRs. For the given modeling scenario, RF, BRF and CNN predict yield by using all the available covariates as explanatory variables in the estimation process. The `grf` package (version 1.2.0 [@tibshirani2018package]) in R was used for RF and BRF modeling. RF and BRF from the `grf` package have several tunable hyperparameters (e.g., the minimum node size in each tree, the number of covariates used for node splitting, and parameters involving an honest tree-building process), the optimal values of which were selected by cross-validation. Individual trees in a forest were built with randomly subsampled observations, leading to a different prediction in every forest even when the same dataset was used. To reduce the variance of predictions for prediction accuracy, the number of trees (*num.trees*) was set at $2000$, a high value.

CNN leaves room for researchers to determine its architecture. We used a slightly modified version of one of the multi-stream CNN architectures proposed by @barbosa2020modeling, called "Late Fusion." Briefly stated, explanatory variables except N rate ($\alpha_{i,j}$, $\beta_{i,j}$, etc.) entered the model as a set of $6 \times 6$ element rasters. The input size of the N rate was treated as $1 \times 1$ because it was spatially homogeneous within each subplot. First, each input was connected to an independent convolutional layer with eight $3 \times 3$ filters of stride one, followed by a $2 \times 2$ max-pooling layer of stride two. Then, a fully-connected rectified linear unit (ReLU) layer with sixteen neurons was added after each max-pooling layer, followed by a single ReLU neuron. Finally, multiple neurons were concatenated and fed to the fully-connected ReLU layer with sixteen neurons, followed by an output with a linear activation function. @barbosa2020modeling demonstrated that this architecture modeled crop yield response to N rate management best among several CNN architectures. CNN was implemented in Python v3.7.6 using Pytorch v1.7.0 [@paszke2017automatic]. The Adam optimizer [@kingma2014adam] was used with a learning rate of $0.001 \%$ (default value). To avoid over-fitting, early stopping was used to monitor validation loss with a ten epochs of patience. (See Figure D.1 in Appendix D for an illustration of the convergence of training with respect to the number of epochs.) 

Let $\mathbf{\Omega_{i}}$ denote a list of subplot-level explanatory variables (soil/field characteristics). Let $\hat{g}_m(N,\mathbf{\Omega})$ denote a yield response function estimated by model $m$ ($m$ = RF, BRF, or CNN). The estimated yield response function at $i$ from model $m$ is $\hat{g}_m(N,\mathbf{\Omega_{i}})$. The site-specific EONR for each model can then be found by solving the following profit maximization problem for all $i$ for each of the models:

\begin{equation}
\hat{N}^{opt}_{i} = \operatorname*{argmax}_{N}(p \cdot\hat{g}_m(N, \mathbf{\Omega_{i}}) - w \cdot N), (\#eq:eqn5)
\end{equation}

where $p$ and $w$ are the prices of corn and N.

### Training and Estimation of Site-specific EONRs by CF

Unlike RF, BRF, and CNN, CF estimates the impact of a binary treatment. In our context, CF estimates changes in yields (i.e., $\hat{\tau}_{N^{con} \rightarrow N^{tre}}(\mathbf{\Omega_{i}})$) caused by changes in N application rates from one experimental rate (the control N rate, denoted $N^{con}$) to another experimental rate (a treatment N rate, denoted $N^{tre}$). Since we have five N application rates, four "experiments" (treatments) are identified based on four ($N^{con}$, $N^{tre}$) combinations. A possible grouping to make such pairwise N application rate combinations, which we call the "CF-base," used $(N_1, N_2),(N_1, N_3),(N_1, N_4)$, and $(N_1, N_5)$. In this approach, the treatment effect is always estimated against the lowest N rate ($N_1$) as $N^{con}$. The `grf` package (version 1.2.0 [@tibshirani2018package]) in R was used for CF estimation. Just like RF and BRF, hyperparameters were tuned using cross-validation.

For estimating site-specific EONR, the trained CF-base were used to predict site-specific changes in yields resultant from changes in application rates from $N_1$ to $N_m$ $(m\in\{2,3,4,5\})$. Let $\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega_{i}})$ be the the estimated treatment effect of changing subplot $i$'s application rate from $N_1$ to $N_m$ for site $i$. Since the CF-base approach always estimates the treatment effects using the lowest treatment rate $N_1$, the predicted treatment effects already represent differences in yields from yield at $N_1$:

\begin{equation}
\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega_{i}}) = \hat{\tau}_{N_{1} \rightarrow N_{m}}(\mathbf{\Omega_{i}}). (\#eq:eqn6)
\end{equation}

With the treatment effects from the base obtained, site-specific EONRs were identified by finding the N rate resulting in the highest profit for each $i$. Yield levels were not predicted at any point in the CF-based approaches.


### Evaluation of yield and EONR predictions

In every simulation round a dataset from a different simulation round was used as the test dataset for evaluation of yield and EONR predictions. This process works because the training datasets were generated by the same data generating process, yet had different underlying field parameters ($\alpha$, $\beta$, $ymax$). Further, all training datasets were generated independently, so for any particular simulation round, the dataset from any other round could serve as a valid test dataset. This practice made the creation of one thousand additional simulations fields unnecessary.

The accuracy of EONR estimation was judged based on the RMSE ($kg/ha$) of the EONR estimation against the true EONR at the subplot level:

\begin{equation}
\mbox{RMSE of EONR estimation} = \sqrt{\frac{1}{1536}\sum_{i=1}^{1536}(N^{opt}_{i} - \hat{N}^{opt}_{i})^2}. (\#eq:eqn7)
\end{equation}

We also used the EONR estimates to calculate $\hat{\pi}_{def}$, estimated per-ha profit-deficits relative to the true maximum profit at the subplot level, defined as profit under the true yield response functions evaluated at $N^{opt}_{i}$. For RF, BRF, and CNN, the accuracy of yield prediction was judged based on the RMSE ($kg/ha$) of the yield prediction against the true yields at the subplot level:

\begin{equation}
\mbox{RMSE of yield prediction} = \sqrt{\frac{1}{1536}\sum_{i=1}^{1536}(y_{i} - \hat{y}_{i})^2}. (\#eq:eqn8)
\end{equation}


# Results and Discussions

## Comparison of EONR Estimation Accuracy

Table \@ref(tab:table-optN) shows the mean RMSE of the EONR estimation and $\hat{\pi}_{def}$ over the one thousand simulations; it makes immediately clear that CF-base considerably outperformed the other ML methods, and that the profits based on CF-base's EONR estimates were the closest to the true maximum profits. BRF performed considerably better predicting EONR than did RF.

<br>

```{r table-optN, tab.cap = "Mean RMSE of EONR (kg/ha) estimation and profit-deficit ($/ha) by ML method and modeling scenario"}
report_table_optN
```

<br>

Interestingly, CNN completely failed in its estimations of site-specific EONRs. This happened because the site-specific yield response functions identified by CNN were linear, and all with the same slope. Therefore, CNN failed to capture a declining marginal product of N. The constant marginal product caused the estimated EONR to take on either the lowest or highest experimental N application rate. We also tested another CNN model to examine whether this problem resulted solely from the specific choice of CNN architecture, which was analogous to CNN-ST proposed by @barbosa2020modeling. This architecture also estimated that yield and N rates were linearly related, and so estimated site-specific EONR poorly. Note that @barbosa2020modeling just compared models through the lens of yield prediction but did not use the estimated models to derive EONRs. @barbosa2020risk extended @barbosa2020modeling's CNN-LF models to estimate site-specific EOIRs for N and seed. But they did not evaluate the accuracy of the EOIR estimates generated by their models. EOIR validation is infeasible using real-world data because ground-truthed site-specific EOIRs are unobservable.

Figures \@ref(fig:dist-optN) and \@ref(fig:dist-piLoss) show the distributions of the RMSEs of the EONR estimations and $\hat{\pi}_{def}$ obtained from the one thousand simulation rounds by the ML method and the modeling scenario, respectively. The center of distribution mass of the CF-base's RMSE values and $\hat{\pi}_{def}$ are to the left of the centers of the distribution masses of the other methods' RMSE values, showing that CF-base more accurately and consistently estimated EONR across all modeling scenarios. 
Interestingly, RF seems particularly vulnerable to the inclusion of more variables, with RMSE ($\hat{\pi}_{def}$) increasing from `r table_optN_prep[type=="test" & Model=="aby",rmse_optN_RF]` (`r table_optN_prep[type=="test" & Model=="aby", pi_loss_RF]`) in the "aby" scenario to `r table_optN_prep[type=="test" & Model=="aabbyytt", rmse_optN_RF]` (`r table_optN_prep[type=="test" & Model=="aabbyytt", pi_loss_RF]`) in the "aabbyytt" scenario. CF-base was more robust to the inclusion of additional variables. Overall, the simulations present CF-base as the clear winner in estimating EONR. 

```{r dist-optN, fig.width=6, fig.height=7, fig.cap = "Distributions of RMSE of EONR estimation over simulations"}
plot_dis_optN
```

```{r dist-piLoss, fig.width=6, fig.height=7, fig.cap = "Distributions of profit deficit over simulations"}
piLoss_density
```

<br>

Figure \@ref(fig:plot-tre) illustrates the underlying cause of CF-base's superior EONR predictions. For one of the one thousand simulation rounds, it plots the estimated treatment effects against true treatment effects by treatment type and ML method under the "aabbyytt" scenario, and shows that CNN substantially underestimates the impact of N. RF also underestimates the impact of N. Underestimation of the impact of N generally leads to the underestimation of EONR, which in turn results in profit loss. Underestimation bias from BRF is less pronounced than from RF and CNN. However, unlike RF, BRF, and CNN, points for CF-base clustered around the red 1-to-1 line, meaning that the estimations of treatment effects did not exhibit significant bias. Moreover, points are clustered more tightly about the 1-to-1 line for CF-base than BRF. That is, CF-base estimated treatment effects more efficiently than did BRF. To check for model robustness, simulations were also run assuming smaller and larger error term sizes. Results presented in Appendix G show qualitative results basically unchanged. 

```{r plot-tre, fig.width=7, fig.height=5, fig.cap = "True treatment effects vs estimated treatment effects (scenario: aabbyytt)"}
figure_te
```

`r ftext('NOTE: The red line in the figures denotes the 1-to-1 line to show the ideal relationship between true and estimated treatment effects.', fp_text(font.size = 9, font.family = "Times New Roman"))`


## The Relationship between Yield and EONR Prediction Performances.

Table \@ref(tab:table-y) shows the mean RMSE of yield prediction over the one thousand simulations. (See Figure E.1 in Appendix E for examples of visualizations of predicted and true yields along with RMSE values, by model.) Since CF-base does not predict yield, the table only reports the results from RF, BRF and CNN. Compared to the result of EONR estimation, RF performed as well as BRF in the simple modeling scenarios of "aby" and "abytt." This fact, along with the poor performance of RF in predicting EONR presented in \@ref(tab:table-optN), shows that strong predictive power of yield levels does not imply accurate prediction of EONR. Further, RF shows vulnerability to the inclusion of many correlated variables, as is displayed for EONR prediction as well. While CNN performed worse than RF and BRF in "aby" and "abytt," it performed better than RF in more complicated modeling scenarios, showing robustness, at least in yield prediction, to inclusion of many correlated variables. Of course, while on average in the "aabbyy" and "aabbyytt" scenarios CNN predicted yields better than RF did, CNN's EONR predictions were worse than RF's, which further backs our claim that a good yield prediction capability does not imply good EONR prediction capability.

<br>

```{r table-y, tab.cap = "Mean RMSE of yield prediction (kg/ha) by ML method and modeling scenario"}
report_table_y
```

By illustrating the distinction between yield prediction at observed points and yield response function prediction, Figure \@ref(fig:vis-MB-BRF-y) provides insight into why good yield level prediction does not necessarily lead to good EONR prediction in general. The black curves are the true yield response functions for two sites in a single simulation round. Red symbols represent true (circle) or predicted (triangle) yields at the rate observed in the data: the rate that was actually applied in the experiment. That is, 150 kg/ha were applied to the two sites in the experiment. Blue symbols represent true (circle) or predicted (triangle) yield at some rates that were not observed (or applied) for the two sites in the experiment. Prediction-oriented ML methods train models to minimize errors in yield level prediction at the "observed" rates (red points). Both RF- and BRF-trained models predicted yield level at the observed rate well for the two sites (the vertical distance between the red circle and triangle). However, moving the N rate away its observed value tends to increase yield prediction error sizes. More importantly, connecting the predicted yield points does not trace the true yield response curves well for either RF or BRF. Specifically, in this example, the predicted impact of N on yield from RF and BRF are both smaller than the true impact. 

```{r, vis-MB-BRF-y, fig.width=7, fig.height=5, fig.cap = "The difference between yield level prediction and yield response prediction (scenario: aabbyytt)"}
vis_MB_BRF_y
```

In essence, Figure \@ref(fig:vis-MB-BRF-y) illustrates that good performance in predicting yield "levels" at the "observed" points does not mean good performance in predicting the yield "response" function, which is about finding out what would have happened to yield had N rates other than the one actually applied been applied. Such poor performance can happen when the wrong variables are credited for driving yield results. The training process of prediction-oriented ML methods may twist the reasonings of why yield varies in a way that sacrifices its ability to recover yield response function as long as it fits its primary objective of predicting yield levels well at the "observed" N rate for each site well. This problem is also observable at Figure \@ref(fig:plot-tre), which shows both RF and BRF underestimate the impact of N on yield: or in other words, their predicted site-specific yield response functions tend to be too flat. Of course, the CNN approach in our study is an extreme case which completely fails to recognize the contribution of N on yield. But Table \@ref(tab:table-y) shows that CNN capable of even outperforming RF and BRF in yield prediction.

Since you need to be able to estimate yield curves (yield response function) well at the site level to predict site-specific EONR (not yield level) well, a model's ability to predict yield levels well at the observed N rates does not guarantee its ability to predict site-specific EONR well. In contrast to RF, BRF, and CNN, CF focuses on recovering the yield response functions well (or alternatively the causal impact of N on yield at different discrete rates of N). We showed that CF can predict the impact of N on yield when N is changed from an unobserved rate to another, as shown in Figure \@ref(fig:plot-tre), which then translated to better performance in predicting EONR and profit.

All previous research has followed a two-step procedure to estimate site-specific EONRs. The first step was to select the model that predicts yield levels most accurately at the observed N rates, and the second was to use the selected model to predict EONR. As discussed earlier, this practice can be economically harmful. Figure \@ref(fig:vis-RMSE-y-eonr) further illustrates the underlying problem. It plots RMSE of yield (x-axis) and EONR (y-axis) predictions by model and simulation round for several simulation rounds. Clearly, the model with the lowest yield RMSE is not necessarily the model with the lower EONR RMSE for a given simulation round (simulation round 20 and 30).

```{r, vis-RMSE-y-eonr, fig.width=5, fig.height=5, fig.cap = "The Relationship between yield and EONR Prediction Performances under the aabbyytt scenario"}
vis_RMSE_y_eonr
```

Table \@ref(tab:count-table) summarizes the relationship between the yield prediction RMSE and the EONR prediction RMSE for all the simulation rounds. It shows clearly that following the process would lead to the choice of the best (as measured by profit) EONR prediction model in fewer than $30\%$ of the "aby" and "abytt" simulation rounds, $40\%$ of the "aabbyy" simulation rounds, and $50\%$ of the "aabbyytt" simulation rounds. For example, the table shows that, in the "aby" scenario, RF attained the lowest RMSE for yield prediction in `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` of 1000 iterations, and attained the lowest $\hat{\pi}_{def}$ in `r summary_res_CNN_RF_BRF[Model=="aby", count_RF]` of those `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` iterations. That is, in `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]-summary_res_CNN_RF_BRF[Model=="aby", count_RF]` out of `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` rounds, the RF model performed the best at yield prediction among RF, BRF, and CNN, but did not provide EONR estimates that led to the highest profit. Similarly, in no case did the CNN method provide both the best yield prediction and the best EONR estimation simultaneously. In the rounds in which BRF predicted yield best, the two-step process worked well. For example, Table \@ref(tab:count-table) shows that BRF predicted EONR best in `r summary_res_CNN_RF_BRF[Model=="aby", count_BRF]` of the `r summary_res_CNN_RF_BRF[Model=="aby", count_y_BRF]` "aby" simulation rounds in which it predicted yields best. But BRF predicted yields best in fewer than $30\%$ of the rounds, implying that the two-step procedure failed more than $70\%$ of the time. 

\newpage

```{r count-table, tab.cap = "Relationship between the EONR prediction performances (as measured by profit) and the yield prediction performances of prediction-oriented ML methods"}
report_summary_res_CNN_RF_BRF
```

<br>

Virtually all previous studies have used yield prediction accuracy to rank and select models. This is understandable, since whereas yield can be "ground-truthed" the true causal impact of a treatment cannot be determined from real-world data, making it impossible to cross-validate EONR prediction. However, the simulation results reported here show clearly that using a model's yield prediction accuracy as a model selection criterion is not well justified if the ultimate objective is accurate estimation of site-specific EONRs. 

# Limitations and Future Studies

Despite the relatively simple nature of the simulations, results reported provide intriguing evidence of potential advantages of CF over other ML methods when the ultimate goal of the OFPE is to increase the economic efficiency of input management. Of course, the reported research did not model all situations, and further research is needed. First, a drawback of the CF method is that because it does not estimate a continuous yield response function, it can only compare the economic outcomes of a limited set of experimental N rates included in the field trial that provides the data. This raises important questions about trial design. How many distinct experimental input application rates should be included? All the trial designs examined here were based on five N rates. Having examined models with additional rates would have increased the number of possible N rates from which the EONR were selected, but reduced treatment pair replications and estimation accuracy.

Second, the size of the field used in the OFPE can affect the relative performances of the competing methods. CF requires honest sampling for its unbiasedness property. Honest sampling comes at the cost of losing prediction accuracy of treatment effects because fewer samples are used to estimate treatment effects within leaves [@athey2016recursive]. Therefore, in the case in which ML analyses are conducted with OFPE data from a small field, CF may not outperform other ML methods

Third, another interesting subject for future research is the potential of combining ML methods with post-estimation spatial smoothing of the estimated EONR. It is well known that soil/field characteristics are spatially correlated [@f2007methods;@goovaerts1999geostatistics]; this spatial correlation is likely to cause spatial correlation in EONRs, which would suggest that post-estimation spatial smoothing of EONRs may further improve the accuracy of EONR estimation.

Finally, a natural and fruitful extension of the reported research would be to test CF and other ML methods in a dynamic setting on which multiple years of experiments are conducted, allowing weather events into the analysis as explanatory variables. Crop simulation models (e.g., APSIM, DSSAT) could replace the Mitscherlich-Baule production function used here to model the underlying yield response function, which could generate more realistic data, using actual soil/field characteristics and weather instead of abstract parameters in the analysis, and so better include the dynamic nature of cropping systems in the study of N management [@archontoulis2020predicting;@puntel2016modeling;@puntel2018systems].

# Conclusion

ML methods are appealing tools that can potentially improve site-specific input rate management by capturing heterogeneous treatment effects introduced by complex non-linear and multidimensional interactions of soil and field characteristics. Several kinds of prediction-oriented ML methods have been used for this purpose. We have introduced the use of CF, a relatively new method, which, unlike prediction-oriented ML methods, focuses on the identification of heterogeneous causal effects of treatment.

We examined the use of CF in the generation of site-specific input management recommendations. Using Monte Carlo simulations under various modeling scenarios, we compared the CF estimations of site-specific EONRs to those of the prediction-oriented ML methods RF, BRF, and CNN. CF consistently outperformed the other methods across all modeling scenarios in terms of EONR prediction and profit generation. Also, it is notable that RF's performance in EONR prediction was considerably worse than BRF's. However, it is important to keep in mind that we are not claiming that CF always performs better economically than RF, BRF, and CNN. Examining the relative performance of CF to the other ML methods in different contexts will be an interesting and fruitful future research. In particular, CNN is extremely flexible in its architecture, and it is possible that other architectures than the one tried in this study may perform much better. 

We also showed that the best model in prediction yields is not necessarily the best model in predicting EONRs and profit generation, implying that yield prediction accuracy should not be used as a model selection criterion if the goal of the experiment is to create a site-specific EOIR map. Many studies seek to predict yield level accurately using deep learning methods. Our results question the usefulness of such models in the making of management decisions. Further examinations into these issues are warranted. 


# Acknowledgements

We thank Scott Swinton at Michigan State University for providing helpful comments on this publication. This research was supported by a USDA-NIFA-AFRI Food Security Program Coordinated Agricultural Project, titled "Using Precision Technology in On-farm Field Trials to Enable Data-Intensive Fertilizer Management," (Accession Number 2016-68004-24769), by the USDA-NRCS Conservation Innovation Grant from the On-farm Trials Program, titled "Improving the Economic and Ecological Sustainability of US Crop Production through On-Farm Precision Experimentation" (Award Number NR213A7500013G021), and by the USDA National Institute of Food and Agriculture, Hatch project ILLU-470-333.

\newpage


# References

<div id="refs"></div>


\newpage

# Supplementary Appendix {-}


```{r, child = "appendix.Rmd"}
```