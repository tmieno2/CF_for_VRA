---
title: "Causal Forest Approach for Site-specific Input Management via On-farm Precision Experimentation"
author: Shunkei Kakimoto^[Corresponding author, Department of Agricultural Economics, University of Nebraska-Lincoln 102 Filley Hall 1625 Arbor Drive Lincoln, NE 68583, USA, E-mail address; skakimoto3@hunskers.unl.edu], Taro Mieno^[Department of Agricultural Economics, University of Nebraska-Lincoln, Lincoln, NE 68583, USA], Takashi S. T. Tanaka^[Artificial Intelligence Advanced Research Center, Faculty of Applied Biological Sciences, Gifu University, Gifu 501-1193, Japan], and David S. Bullock^[Department of Agricultural and Consumer Economics, University of Illinois, Urbana, IL 61801, USA]
output:
  bookdown::word_document2:
    fig_caption: yes
    number_sections: yes
    global_numbering: true
    # reference_docx: word_template.docx
    reference_docx: word_template_format.docx
    # pandoc_args: ["-Fpandoc-crossref"]
bibliography: ML_VRA.bib
csl: computers-and-electronics-in-agriculture.csl
eqnPrefix: 
      - "Eq"
abstract: "Estimating site-specific crop yield response to changes in input (e.g., seed, fertilizer) management is a critical step in making economically optimal site-specific input recommendations. Past studies have attempted to estimate yield response functions using various Machine Learning (ML) methods, including the Random Forest (RF), Boosted Random Forest (BRF), and Convolutional Neural Network (CNN) methods. This study proposes use of the Causal Forest (CF) model, which is one of the emerging ML methods that comprise \"Causal Machine Learning.\" Unlike previous prediction-oriented ML methods, CF focuses strictly on estimating heterogeneous treatment effects of inputs, rather than predicting yield. We report results of using Monte Carlo simulations assuming various production scenarios to test the effectiveness of CF in estimating site-specific economically optimal nitrogen rates (EONRs), comparing CF with the yield-prediction-oriented ML methods RF, BRF, and CNN. CF's estimations of site-specific EONRs were superior under all scenarios considered. Furthermore, we also show that the quality of a model's yield predictions provides little if any information about the quality of its EONR predictions."  
---

```{r echo = F, results='hide', message=FALSE}
library(knitr)
library(here)

# === set wd ===#
# Notes: not really necessary to set the working directory as long as this Rmd file is part of an R project and the evaluation directory was set to "Project".

opts_knit$set(root.dir = here())
# setwd(here())
# opts_knit$set(root.dir = "~/OneDrive - University of Nebraska-Lincoln/ML_VRA")

options(htmltools.dir.version = FALSE)
options(knitr.duplicate.label = "allow")

opts_chunk$set(
  fig.align = "center", 
  fig.retina = 5,
  warning = F, 
  message = F,
  cache = FALSE, # <-- T
  cache.lazy = FALSE,
  echo = F
  )
```

```{r, cache = TRUE}
# === packages ===#
library(sf)
library(png)
library(data.table)
library(grf)
library(RColorBrewer)
library(patchwork)
library(plotly)
library(magrittr)
library(ggplot2)
library(viridis)
library(tmap)
library(tidyverse)
library(ggthemes)
library(mgcv)
library(ggpubr)
library(flextable)
library(officer)
library(officedown)
library(modelsummary)
library(raster)
library(bookdown)
```

```{r analyses, results = "hide", fig.show='hide', cache = FALSE}
#/*=================================================*/
#' # Preparation
#/*=================================================*/
# This is where you prepare data sets and results 

#/*----------------------------------*/
#' ## Create figures and tablesb
#/*----------------------------------*/
# --- Convert an Rmd file into a pure R file using purl() ---#
knitr::purl(here("GitControlled/Codes/PrepareResults.Rmd"), output = here("GitControlled/Codes/PrepareResults.R"))

# --- Read the simulation results and prepare figures and tables ---#
source(here("GitControlled/Codes/PrepareResults.R"))
```

# Keywords: {-}

site-specific input management, nitrogen rate, on-farm precision experimentation, machine learning, causal forest, economically optimal input rates

# Introduction

<!-- + background on nitrogen management (economics, environment, precision agriculture)   -->

<!-- The modern agricultural production system which is featured by the enlargement of fields due to capital-labor substitution, has been confronting the difficulty of considering the spatial and temporal within-field heterogeneity of crop management[@zhang2002precision]. Precision agriculture(PA) is the combination of technologies and practices developed to assist decision-making for such complicated management utilizing the power of information technology[@cook1998precision; @finger2019precision]. One of the leading PA technologies is variable rate application(VRA), and it has been actively investigated for site-specific input management, especially for nitrogen and seed management [@Khosla2002; @shanahan2004feasibility; @ruffo2006site; @koch2004economic; @ping2008site; @shanahan2008responsive; @munnaf2020site ;@munnaf2021map].
Efficient management of N fertilizer is a critical component of crop production from the agronomic, economic, and environmental standpoints. Inappropriate amount or timing of N application adversely affects both biomass yields and grain quality for some crops. Furthermore, inefficient use of N fertilizer not only results in economic loss but causes ambient environmental degradation[@blumenthal2008importance; @dinnes2002nitrogen; @tremblay2006adapting]. \ -->

Despite the potential economic and environmental benefits of site-specific input (e.g., nitrogen (N), seed) management, the adoption rate of variable rate application technology remains relatively low [@lowenberg2019setting]. 
This is primarily because of the difficulty in estimating site-specific yield response functions accurately within a field, which is critical for the identification of site-specific economically optimal input rates (EOIRs) [@bullock1998does].

Historically, site-specific yield response functions have been estimated using the data generated from strip trials conducted on only parts of fields [@makowski2001statistical; @scharf2002corn; @bullock2002adding; @mamo2003spatial; @hurley2004estimating; @anselin2004spatial; @scharf2005field; @ruffo2006site; @Miao2006; @puntel2019development].
But recently whole-field on-farm precision experimentation (OFPE) [@bullock2019] has allowed implementation of improved statistical experimental designs (e.g., Latin Square, Randomized Block) are used for an entire field [@laurent_kyveryga_makowski_miguez_2019; @licht_witt_2019]. Data generated from whole-field OFPEs typically have greater local variation in experimental input application rates and soil/field characteristics than do strip trial designs, which has improved the statistical identification of heterogeneous impacts of input management changes on yields. The resultant availability of more spatially detailed experiment data has encouraged a resurgence of interest in estimating site-specific yield response functions. For example, @barbosa2020modeling, @krause2020random and @Gardner21 used OFPE data to estimate site-specific yield response functions and economically optimal site-specific N fertilizer and/or seed rates. These recent studies used machine learning (ML) methods extensively in place of more traditional parametric modeling approaches. @barbosa2020modeling applied the Convolutional Neural Network approach, @krause2020random used Random Forest-based approaches, and @Gardner21 used the shape-constrained generalized additive model. But this trend of applying ML methods may raise concerns. Historically, agronomy is a field that has paid meticulous attention to identifying the "causal" impacts of input management on yield through clever experimental designs. But the aforementioned recent applications of ML methodologies pay little attention to causal identification of inputs on yield, instead validating their models by yield prediction accuracy. But the ultimate goal of OFPE is the accurate prediction of EOIRs, not yields. These are distinct objectives, and achievement of one need not imply the other.

The lack of and need for causal interpretation of the results of ML research applications have been increasingly recognized, in particular in economics and medicine [@athey2017beyond; @athey2018impact; @Athey2019a; @moraffah2020causal; @Storm2020; @arti2020research; @scholkopf2021toward]. In response, causal machine learning (CML) methods were recently developed. Unlike traditional prediction-oriented ML methods, CML focuses on identifying causal impacts of an event (in our context, an increase or decrease in the input application rate). The growing academic literature applying CML methods includes @richens2020improving, who pointed out that the inability of the traditional ML methods to identify cause and effect relationships between disease and patients' characteristics could lead to misdiagnoses, and showed that CML-based diagnoses could improve the accuracy of diagnostic prediction. In addition, @carbo2020machine used a CML to identify characteristics causing bank customers to adopt online banking services, and @bozorgi2020process applied CML to study the mining processes.

In this paper, we test the accuracy of site-specific economically optimal N fertilization rates (EONRs) estimation based on Causal Forest (CF) approach developed by @athey2016recursive and @Wager2018a. We compare the EONR prediction performances of our CF-based approach to the widely used ML methods Random Forest (RF), Boosted Random Forest (BRF), and Convolutional Neural Network (CNN). Further, we also test how yield prediction performance is related to EONR prediction performance to examine whether it is appropriate to select the model based on its ability to predict yield when the ultimate goal is to identify EOIR. We use Monte Carlo simulations, where we synthetically generate yield and soil/field characteristics datasets for a stylized "field." Because real-world "true" EOIRs cannot be measured, real-world data cannot be used to test the accuracy of statistical methods estimating EOIRs. This important difference contrasts starkly with yield prediction, since actual yields can be ground-truthed.

<!-- Our simulation results reveal that CF-based approaches provide superior performance in site-specific EOIR estimation. We also demonstrate that a method's yeidl prediction accuracy is not a good indicator of its EOIR estimation accuracy. -->

# Predicting Yield vs. Predicting Changes in Yield in Response to Changes in Input Management

In the following, we describe the fundamental information necessary to identify EOIR in general: the site-specific treatment effect of input application on yield. We then discuss the causal forest method in detail, show how it is particularly suitable to obtain this fundamental information, and contrast it to more traditional prediction-oriented ML methods, such as RF, BRF, and CNN.

## A Simple Profit-maximization Problem

Let $p$ be the price that a producer receives for a unit of a crop, $w$ be the per-unit price paid for a unit of an input, $OC$ represent other costs of production, and $y=f(I, \mathbf{c})$ describe the relationship between crop yield, the input application rate $I$ and a vector of field characteristics variables $\mathbf{c}$. A simple model of producer behavior assumes that the producer chooses a level of $I$ to maximize profits (revenues minus costs):

\begin{equation}
\max_{I} \quad pf(I, \mathbf{c}) - wI -OC. (\#eq:eqn1)
\end{equation}

Elementary calculus shows that the necessary condition for maximization is, that $\partial f(I, \mathbf{c})/\partial I - w =0$, which implicitly defines the economically optimal input application rate as a function of prices and soil/field characteristics, and may be arranged as \@ref(eq:eqn2):

\begin{equation}
\frac{\partial f(I^{*}(p,w,\mathbf{c}), \mathbf{c})}{\partial I} \equiv \frac{w}{p}. (\#eq:eqn2)
\end{equation}

Identity \@ref(eq:eqn2) states that the necessary elements of the information needed for profit maximization are the input price, the output price, and the partial derivative of the yield function with respect to the input. While knowledge of the yield function $f(I, \mathbf{c})$ in Eq. \@ref(eq:eqn1)) is sufficient to solve the maximization problem above (since its derivative can be calculated), identity \@ref(eq:eqn2) shows that it is not a necessary condition; rather, knowing the function's partial derivative is necessary.  In the following, we discuss a method of using Causal Forest methods that can provide statistical advantages to the estimation of economically optimal input application rates because it is built to estimate approximations of the derivative $\partial f/\partial I$ directly, and not the yield function $f$ itself.

## Estimating EOIR and Treatment Effects

Recent papers using ML methods to estimate the effectiveness of various agricultural input management strategies have based their analyses on estimates of a yield function, $f(I, \mathbf{c})$ (e.g., @krause2020random; @barbosa2020modeling; @Gardner21). In the following, we present a Causal Forest methodology that does not rely on estimation of how the level of yield depends on the input application rate $I$, but rather relies on a discrete version of Eq. \@ref(eq:eqn2), examining the discrete changes in yield that result from discrete *changes* in the input application rate $I$. 

Consider an increasing ordering of input application rates $I_1, I_2,...,I_K$. Among these K rates, for a generic site $i$ a specific EOIR can be identified if the *treatment effect* function $\Delta y_i(I_{k+1}, I_{k})$ is known. This function is defined as the discrete change in yield that results from a discrete change in the input level from $I_k$ to $I_{k+1}$, and it depends on the characteristics at the site analyzed: 

$$
\Delta y_i(I_{k+1}, I_{k}) = f(I_{k+1}, \mathbf{c_i}) - f(I_{k}; \mathbf{c_i}) \quad ^\forall k = 1, \dots , K - 1
$$

Once treatment effects $\Delta y_i(I_{k+1}, I_{k})$ have been identified for every $k$, economic analysis can be conduced to identify the EOIR for site $i$. The profit change from increasing the input rate from $I_{1}$ to $I_{k}$ is 

$$
P_c (\sum_1^{k-1} \Delta y_i(I_{k+1}, I_{k})) - P_I \times (I_k - I_0).
$$

The EOIR is the value $I_k$ that maximizes the profit gain "relative" to profits from $I_1$. ($I_1$ may be the EOIR if no other rates surpass the profit of $I_1$.)

## Causal Forest

CF was developed specifically for identifying heterogeneous treatment effects [@athey2016recursive; @Wager2018a]. Like RF, CF works by building an ensemble of trees, called *causal trees* (CT), by recursively partitioning covariate space into two leaves, where each leaf estimates conditional average treatment effects as the mean differences between the dependent variable (here, yield) of the treated and control observations that belong to the leaf. Figure \@ref(fig:ct-ex) shows an example of CT where the treatment is an increase in seed rate from $27,000$ seeds/ha (control) to $31,000$ seeds/ha (treated) with apparent electrical conductivity ($\textit{ecs}$) and topographical $\textit{slope}$ as variables to explain the heterogeneity of the impact of the treatment impact. 
In the first node, all the samples ($1024$ observations) belong to the node, and the causal effect of the treatment was calculated as the difference in the mean yield of the treated and control groups, which turned out to be $593$ kg/ha in this example. 

```{r ct-ex, fig.width=4, fig.height=4, fig.align="center", fig.cap = "An Illustrative Example of Causal Tree"}
knitr::include_graphics(here("GitControlled/Writing/JournalSubmission/ctree_ex.png"))
```

The first data split criterion is whether the $\textit{ecs}$ value is greater or less than $25$. The observations with $\textit{ecs}$ greater than or equal to $25$ move to the left node, while those with $\textit{ecs}$ less than $25$ move to the right. For each of the subsamples, the treatment effect is identified as the difference in the mean yields of the treated and control groups within the subsample. The treatment effect for the low-$\textit{ecs}$ observations was $619$ kg/ha, and for the high-$\textit{ecs}$ observations was $982$ kg/ha. This means that for the impact of the increase in seed rate the treatment effect is heterogeneous over space, having a larger positive impact on yield in high-$\textit{ecs}$ areas. Trees are further developed to have more groups of subsamples to allow for more flexible representations of the heterogeneous treatment effects. The estimated CF model does not predict yield level at any site $i$ in the field, but rather estimates site-specific EOIRs by estimating treatment effects. Since CF is designed to estimate the causal effect of an input directly, it may be suspected that CF will outperform other ML methods that identify EOIR indirectly through yield prediction.

While both RF and CF build trees by recursively partitioning samples, they differ critically in their criteria for splitting. In RF, the sample is split to minimize the mean squared error (MSE) of yield prediction in building trees. Unfortunately, the MSE of treatment effect predictions is not useful for building a CT since the true treatment effects are never observable. However, @athey2016recursive showed that minimizing the expected MSE of the treatment effect is equivalent to maximizing the variance of treatment effects across the resulting two leaves and minimizing the within-leaf variance. Consequently, by splitting samples in a way that maximizes the variance of treatment effects across the resulting two leaves, CF overcomes the fundamental problem created by the unobservability of true treatment effects. CF requires that the tree-building process is "honest" for treatment effects estimation to be unbiased. Honest tree-building first randomly splits in two the training data samples, then uses one of the subsamples to determine how to split the tree, and uses the other to estimate the treatment effects [@athey2016recursive; @Wager2018a]. This honest subsampling technique avoids overestimation of the heterogeneity of estimated treatment effects. Since CF splits samples to maximize the heterogeneity of estimated treatment effects, using the same sample for both the sample splitting and treatment effect calculations renders itself sensitive to noise or outliers, allowing high noise levels to exaggerate the treatment effects.

## CF vs. Prediction-oriented ML methods

Whether the indirect (yield-prediction-first) and direct approach is used can lead to meaningful statistical differences when it comes to EOIR estimation. The conventional prediction-oriented ML methods are designed to predict yield, $y_i(I,\mathbf{c})$, well, but not necessarily treatment effects. Since the loss function used in prediction-oriented ML uses (typically squared) residuals in yield prediction, prediction-oriented ML is naturally optimized for predicting the "level" of yield instead of identifying the causal impact of the input. CF, on the other hand, is designed specifically to estimate the causal impact of input. Indeed, @Wager2018a used Monte Carlo simulations to show that CF provided more accurate estimates of heterogeneous treatment effects than those provided by RF. However, the underlying data generating process of their simulations was extremely simple, with the treatment effect influenced by only a single variable. CF has never been tested for more complicated data generating processes, such as those represented by yield response functions in which the treatment effect of an input can be affected by multiple variables in a non-linear fashion. Moreover, CF has never been compared to more advanced ML methods such as BRF and CNN that are considered to have prediction capabilities greater than RF's. The study reported here builds on @Wager2018a to compare CF to these prediction-oriented ML methods (not just RF, but also BRF and CNN) in more realistic agronomic experiment settings.


# Materials and Methods

Monte Carlo simulations were conducted for nitrogen experiments for corn production to estimate the economically optimal nitrogen rate (EONR). The first step in our simulation was to generate one thousand synthetic fields that "resembled" an actual field. For each simulated field, we generated a training data set and a validation data set. Field characteristics and yield were simulated based on the Mitscherlich-Baule (MB) yield response function. We used the RF, BRF, and CNN ML methods to estimate yield response functions, and we used the CF method to estimate treatment effects. For each method, we estimated site-specific EONRs using the training data set, and checked the statistical performance of the predicted site-specific EONR using the validation data set. Detailed descriptions of these steps are provided below. The R codes that implement the simulation analyses are available at https://github.com/tmieno2/ML_VRA.git.

## Data Generation

### Simulated Experimental Fields
<!-- experimental field: area: 51ha, plot: 384, subplot:1536, cell:55296   -->
<!-- field with padding: area: 57ha, plot: 476, subplot:1700, cell:61200   -->

The simulated field was created based on an actual 51-ha Illinois field on which the Data-Intensive Farm Management (DIFM) project [@bullock2019] has run multiple OFPEs. Figure \@ref(fig:field-map) illustrates that simulated trials consisted of $384$ 60-ft $\times$ 240-ft "plots," each of which was assigned an N fertilizer application rate. Each plot was made up of four (4-rows $\times$ 1-column) "subplots," which were unit of analysis used in subsequent statistical analysis. Each subplot contained of a 6-rows $\times$ 6-columns grid of thirty-six 10-ft $\times$ 10-ft "cells." All field characteristics and yield data were generated at the cell level.

```{r field-map, fig.width=4, fig.height=3, fig.cap = "Division of Field: plots, subplots and cells"}
knitr::include_graphics(here("GitControlled/Writing/JournalSubmission/field_devision.png"))

```

### Underlying Yield Response Function

We modeled the yield response function as having the following Mitscherlich-Baule functional form:

\begin{equation}
f(N, \mathbf{c}) = ymax(\mathbf{c})(1-exp(\alpha(\mathbf{c}) + \beta(\mathbf{c}) N)) + \varepsilon. (\#eq:eqn3)
\end{equation}

The first term on the right-hand side of Eq. \@ref(eq:eqn3) is the deterministic yield component, which was generated assuming the commonly-used MB functional form, which is flexible in its shape, allows for the existence of a yield plateau, and has been shown to be a plausible specification for N fertilization models for corn [@frank1990; @llewelyn1997; @paris1992].
The variable $N$ in Eq. \@ref(eq:eqn3) represents the nitrogen fertilizer application rate (kg/ha) which the trial designs varied by plot. Also in Eq. \@ref(eq:eqn3), $\alpha$, $\beta$, and $ymax$ are functions of a vector of field characteristics variables $\mathbf{c}=(c_1,...,c_K)$, which vary spatially on the field. For example, $\alpha$ and $ymax$, which affect yield independently from the applied N fertilizer rate, might be interpreted as depending on the ingredient soil N content supplied by residual N, soil organic matter, etc. $\beta$ can be interpreted as reflecting how efficiently the crop uses N to create grain mass, and might depend on soil properties that affect the availability of applied N fertilizer to the crop, say due to N immobilization, leaching, denitrification, and volatilization [@johnson2005nitrogen; @alva2006nitrogen]. The error term of the yield $\varepsilon$ represents the composite of all the unobserved factors that affect crop yield beyond $\alpha$, $\beta$, $ymax$ and $N$. 

A fictional "researcher" is modeled as having limited knowledge about which variables make up $\mathbf{c}$, or even the number of elements of $\mathbf{c}$, and has limited ability to measure the values that many of the variables that constitute $\mathbf{c}$ take on across the field. The researcher is also assumed to not know the functional forms of the yield response function. 


### Cell-specific Yield Functions and Economically Optimal N Rates

Let $i \in \{1,2,...,1536\}$ index a simulated field's subplots and $j \in \{1,2,...,36\}$ index cells within a subplot. Let $N^{i}$ be the N fertilization rate on plot $i$, and let $\mathbf{c}^{i,j}$ be the value of $\mathbf{c}$ on cell $(i,j)$, Eq. \@ref(eq:eqn4) shows the yield level on cell $j$ in subplot $i$ is affected by the N rate applied on subplot $i$:

\begin{equation}
f(N^{i}, \mathbf{c}^{i,j}) = ymax(\mathbf{c}^{i,j})(1-exp(\alpha(\mathbf{c}^{i,j}) + \beta(\mathbf{c}^{i,j}) N^{i})) + \varepsilon^{i,j}. (\#eq:eqn4)
\end{equation}

To simplify notation, denote  $\alpha(\mathbf{c}^{i,j})$ as $\alpha^{i,j}$, $\beta(\mathbf{c}^{i,j})$ as $\beta^{i,j}$, and $ymax(\mathbf{c}^{i,j})$ as $ymax^{i,j}$. Then, a cell-specific yield function can be written as, 

\begin{equation}
f^{i,j}(N) = ymax^{i,j}(1-exp(\alpha^{i,j} + \beta^{i,j} N^{i})) + \varepsilon^{i,j}. (\#eq:eqn5)
\end{equation}

Parameters $\alpha^{i,j}$, $\beta^{i,j}$, $\beta^{i,j}$, and $\varepsilon^{i,j}$ were modeled as spatially autocorrelated using unconditional Gaussian geostatistical simulation based on the spherical variogram model. The `gstat` package (version 2.0.6 [@gstat1; @gstat2]) in R was used for this purpose. Table \@ref(tab:variogram-parameters) shows the main variogram parameter values used in generating $\alpha^{i,j}$, $\beta^{i,j}$, $ymax^{i,j}$, and $\varepsilon^{i,j}$, which were chosen to generate yields consistent with those observed in experiments conducted by the DIFM project (Codes used to generate parameter values are available at https://github.com/tmieno2/ML_VRA.git.) Figure \@ref(fig:fig-parameters) shows an example of the generated parameters. 

<br>

```{r variogram-parameters, tab.cap = "The Parameters for the Variogram Modeling"}
variogram_tb
```

<br>

```{r fig-parameters, fig.width=6, fig.height=5, fig.cap = "An Illustrative Example of Spatial Distributions of Field Characteristics"}
# field_alpha + field_beta + field_ymax
grid.arrange(field_ymax, field_alpha, field_beta, field_m_error, ncol=2, nrow=2)
```

Each cell $(i,j)$'s "true" optimal N application rate, denoted $N_{opt}^{i,j}$, was calculated by solving a profit maximization problem:

\begin{equation}
N_{opt}^{i,j} = \operatorname*{argmax}_{N}(P_{C} f^{i,j}(N) - P_N N), (\#eq:eqn6)
\end{equation}

where, $P_{C}=\$0.138/kg$ and $P_{N}=\$1.323/kg$ were the assumed prices of the corn and N fertilizer. Figure \@ref(fig:fig-optN) maps an example of the identified "true" cell-specific optimal N rates. 


```{r fig-optN, fig.width=3, fig.height=4, fig.cap = "An Illustrative Example of a Spatial Distribution of True Optimal N Rate"}
vis_optN_cell
```

<br>

### Trial Design

In each simulation round, five field-trial N rates were determined based on the range of the round's cell-specific EONRs. 
Let $Q_q$ ($q \in [0,1]$) denote the $100 \times q$ percent quantile of the round's cell-specific EONRs. Then, the five trial design rates were 

$$
\begin{aligned}
N_1 &= Q_{0.05} - 20 \\
N_5 &= Q_{0.95} + 20 \\
N_2 &= N_1 + 0.25(N_5 - N_1) \\
N_3 &= N_1 + 0.50(N_5 - N_1) \\
N_4 &= N_1 + 0.75(N_5 - N_1)
\end{aligned}
$$

In each round, a Latin square design was followed to assign each plot one of the five N rates so established. Figure \@ref(fig:fig-nExp) shows an example of a trial design. 

```{r fig-nExp, fig.width=3, fig.height=4, fig.cap = "An Illustrative Example of Experimental Design of N"}
field_Ndesign
```

Under this design, the N rate was orthogonal to the error term. This is important because if they were correlated, bias in the estimation of the impact of nitrogen on yield would be introduced for all of the ML methods. Since the treatment effect at each leaf is obtained simply by taking the difference of the average value of the dependent variable between the control and treated group within the leaf, CF requires the exogeneity of the treatment conditional on the independent variables to estimate the treatment effect consistently. Note that the violation of this condition leads to biased estimation for not just CF and the other ML methods, as well. 


### Yield Data Generation and Aggregation

A cell-level data set for the whole field, $\{(y^{i,j}, N_{opt}^{i,j}, N^{i,j}, \mathbf{c}^{i,j}): i \in \{1,2,...,1536\}, j \in \{1,2,...,36\}\}$ was generated. For a generic cell $(i,j)$, yield $y^{i,j}$ was generated through Eq. \@ref(eq:eqn3), applying parameter values $\mathbf{c^{i,j}}=(\alpha^{i,j}, \beta^{i,j}, ymax^{i,j})$, the disturbance term level $\varepsilon^{i,j}$, and the cell's assigned experimental N rate, $N^{i,j}$ (Figure \@ref(fig:field-yield-cell)). 

```{r field-yield-cell, fig.width=3, fig.height=4, fig.cap = "An Illustrative Example of a Yield Distribution Map at the Cell resolution"}
vis_yield_cell
```

<br>

These were aggregated up to the subplot level by taking the mean of the cell-level values inside each subplot, which were the unit of observation. The subplot data were therefore 

$$
\{(y^{i}, N_{opt}^{i}, N^{i}, \mathbf{c}^{i}) = \frac{1}{36}\sum_{j=1}^{36} (y^{i,j}, N_{opt}^{i,j}, N^{i,j}, \mathbf{c}^{i,j}): i \in \{1,2,...,1536\}\}
$$

Figure \@ref(fig:field-yield-subplot) shows an example of observed yield data. Note that data generation at the cell level was conducted to reflect the real-world spatial heterogeneity in soil/field characteristics within the subplot level. But data aggregation to the subplot level was conducted because the large sizes of harvesters make it impossible to monitor yields accurately at smaller scales.

```{r field-yield-subplot, fig.width=3, fig.height=4, fig.cap = "An Illustrative Example of a Yield Distribution Map at the Subplot resolution"}
vis_yield_subplot
```

<br>

### Modeling Scenarios

To evaluate the performances of RF, BRF, CNN and CF, we examined four modeling scenarios, each defined by a dataset assumed to be available to the researcher. The first modeling scenario, denoted "aby" assumed that researchers have a dataset of the actual values $\alpha^{i,j}$, $\beta{i,j}$, $ymax^{i,j}$ for every cell $(i,j)$ and use $\alpha$, $\beta$ and $ymax$ as covariates in their ML models. This scenario represents an ideal situation for researchers, in which all the relevant variables are observed, but the true functional form of heterogeneous yield response functions are not known. More realistic scenarios can be compared with this ideal scenario.

In subsequent modeling scenarios, we made the simulated experimental data more realistic by varying the degree to which researchers understood what the needed covariates' values were those in the data set. In the second scenario, denoted "abytt," we introduced additional variables $\theta_1$ and $\theta_2$, and the researcher's dataset contained values of $\alpha^{i}$, $\beta^{i}$, $ymax^{i}$, $\theta_1^{i}$ and $\theta_2^{i}$ for all subplots $i=1,...,1536$. $\theta_1$ and $\theta_2$ had no effect on yield, but their cell-level values were spatially correlated with $\beta^{i,j}$, and so their subplot-level values were correlated with $\beta^{i}$. This scenario is meant to reflect the lack of scientific consensus about which variables explain heterogeneous yield response to N, making it likely that researchers include irrelevant variables like $\theta_1$ and $\theta_2$ in real-world data analysis. 

In the third scenario, denoted "aabbyy," the researcher's dataset did not contain values of $\alpha^{i}$, $\beta^{i}$, or $ymax^{i}$. Rather, it contained subplot-level values of permutations of $\alpha$, $\beta$, and $ymax$. Specifically, for each cell $(i,j)$, we assigned one of a set of spatially autocorrelated weights $r_{\alpha}^{i,j} \in (0,1)$ to the $\alpha$ variable, another set of spatially autocorrelated weights $r_{\beta}^{i,j} \in (0,1)$ to the $\beta$ variable, and another set of spatially autocorrelated weights $r_{ymax}^{i,j} \in (0,1)$ to the ${ymax}^{i,j}$ variable. (There was no spatial correlation between the $r_{\alpha}^{i,j}$ and $r_{\beta}^{i,j}$ data, between $r_{\alpha}^{i,j}$ and $r_{ymax}^{i,j}$ data, or between $r_{\beta}^{i,j}$ and $r_{ymax}^{i,j}$.) Six new covariates were created with the weights and the original covariates $\alpha^{i,j}$, $\beta^{i,j}$ and $ymax^{i,j}$. 
These were 
$\alpha_{1}^{i,j} = r_{\alpha}^{i,j} \alpha^{i,j}$, $\alpha_{2}^{i,j} = (1- r_{\alpha}^{i,j}) \alpha^{i,j}$,
$\beta_{1}^{i,j} = r_{\beta}^{i,j} \beta^{i,j}$, $\beta_{2}^{i,j} = (1- r_{\beta}^{i,j}) \beta^{i,j}$,
$ymax_{1}^{i,j} = r_{ymax}^{i,j} ymax^{i,j}$, and $ymax_{2}^{i,j} = (1- r_{ymax}^{i,j}) ymax^{i,j}$.
For each $\alpha$, $\beta$ and $ymax$, these procedures created two new covariates that were highly spatially autocorrelated with the original covariate, which was meant to reflect that many of the soil/field characteristics used to analyze OFPE data are spatially correlated. The values of $\alpha^{i,j}$, $\beta^{i,j}$ and $ymax^{i,j}$ did not indicate specific soil or field characteristics, but were functions of such. In reality, scientists cannot directly observe variables that can accurately predict yield plateau level, soil N content and N uptake efficiency. Rather, they use multiple observed soil/field characteristics to explain such phenological phenomena. For example, instead of using $ymax^{i,j}$ directly, some some topographical land features and soil properties such as elevation and soil sand content could be used as yield-limiting factors [@jiang2004effect; @kravchenko2000correlation]. In reality, scientists may include more than three variables as covariates. This scenario should reduce the accuracy of EONR modeling for all the models compared to the ideal case. 

The fourth scenario, denoted "aabbyytt," had the same components as aabbyy, but also included the $\theta_1$ and $\theta_2$ covariates. 


## OFPE Experiments and Estimating Site-specific Optimal N Rates

### RF, BRF, and CNN

The RF, BRF, and CNN methods followed the same conceptual steps to estimate site-specific EONR: 1) estimate the yield production functions and 2) calculate site-specific EONRs based on that estimated function. For the given modeling scenario, RF and BRF predict yield by using all the available covariates as explanatory variables in the estimation process. The `grf` package (version 1.2.0 [@tibshirani2018package]) in R was used for RF and BRF modeling.

CNN leaves room for researchers to determine its architecture. In this article, a slightly modified version  of one of the multi-stream CNN architectures proposed by @barbosa2020modeling, called "Late Fusion," was used. Briefly stated, explanatory variables except N rate (e.g. $\alpha^{i,j}$, $\beta^{i,j}$, etc.) enter the model as a set of $6 \times 6$ element rasters. On the other hand, the input size of the N rate is treated as $1 \times 1$ because it is spatially homogeneous within each subplot. First, each input was connected to an independent convolutional layer with eight $3 \times 3$ filters each with stride one, followed by a $2 \times 2$ max-pooling layer with stride two. Then, a fully-connected rectified linear unit (ReLU) layer with sixteen neurons was added after each max-pooling layer, followed by a single ReLU neuron. Finally, multiple neurons were concatenated and fed to the fully-connected ReLU layer with sixteen neurons, followed by an output with a linear activation function. @barbosa2020modeling demonstrated that among several CNN architectures, this architecture modeled crop yield response to N rate management best. CNN was implemented in Python v3.7.6 using Pytorch v1.7.0 [@paszke2017automatic]. The Adam optimizer [@kingma2014adam] was used with a learning rate of $0.001 \%$ (default value). To avoid over-fitting, early stopping was used to monitor validation loss with a ten epochs of patience. 

Let $\mathbf{\Omega^{i}}$ denote a list of subplot-level explanatory variables (soil/field characteristics). Further, let $\hat{g}_m(N,\mathbf{\Omega})$ denote an estimated yield response function, estimated by model $m$ ($m$ = RF, BRF, or CNN). Then, yield at $i$ from model $m$ is $\hat{g}_m(N,\mathbf{\Omega^{i}})$. The site-specific EONR for each model can then be found by solving the following profit maximization problem for all $i$ for each of the models:

$$
\hat{N}_{opt}^{i} = \operatorname*{argmax}_{N}(P_{C} \hat{g}_m(N,\mathbf{\Omega^{i}}) - P_N N) 
$$

where $P_C$ and $P_N$ are the prices of corn and N.

### CF

Unlike RF, BRF, and CNN, CF estimates the impact of a binary treatment. 
In our context, CF estimates changes in yields (i.e., $\hat{\tau}_{N^{con} \rightarrow N^{tre}}(\mathbf{\Omega^{i}})$) caused by changes in N application rates from one experimental rate (control N rate, i.e., $N^{con}$) to another experimental rate (treatment N rate, i.e., $N^{tre}$). Since we have five N application rates, four "experiments" (treatments) are identified based on four ($N^{con}$, $N^{tre}$) combinations. A possible grouping to make such pairwise N application rate combinations, which we call the "CF-base," used $(N_1, N_2),(N_1, N_3),(N_1, N_4)$, and $(N_1, N_5)$. In this approach, the treatment effect is always estimated against the lowest N rate ($N_1$) as $N^{con}$.

For estimating site-specific EONR, the trained CF-base were used to predict site-specific changes in yields resultant from changes in application rates from $N_1$ to $N_m$ $(m\in\{2,3,4,5\})$. Let $\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega^{i}})$ be the the estimated treatment effect of changing subplot $i$'s application rate from $N_1$ to $N_m$ for site $i$. 

Since the CF-base approach always estimates the treatment effects using the lowest treatment rate $N_1$, the predicted treatment effects already represents the change in yields from the yield at $N_1$:

$$
\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega^{i}}) = \hat{\tau}_{N_{1} \rightarrow N_{m}}(\mathbf{\Omega^{i}})
$$

With the treatment effects from the base obtained, site-specific EONRs were identified by finding the N rate resulting in the highest profit. Yield levels were not predicted at any point in the CF-based approaches.

<!-- We consider two possible groupings to make such pairwise N application rate combinations.  The first grouping approach, which we call the "CF-base", used $(N_1, N_2),(N_1, N_3),(N_1, N_4)$, and $(N_1, N_5)$. In this approach, the treatment effect is always estimated against the lowest N rate ($N_1$) as $N^{con}$. The second grouping approach used $(N_1, N_2),(N_2, N_3),(N_3, N_4)$, and $(N_4, N_5)$. We label this approach as the "CF-stepwise". 
For estimating site-specific EONR, the trained CF-base and CF-stepwise methods were used to make predictions of site-specific changes in yields resultant from changes in application rates from $N_1$ to $N_m$ $(m\in\{2,3,4,5\})$. Let $\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega^{i}})$ be the the estimated treatment effect of changing subplot $i$'s application rate from $N_1$ to $N_m$ for site $i$. 
In the CF-stepwise approach, this value can be calculated by sequentially adding the estimated treatment effects: 
$$
\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega^{i}}) = \sum_{k=1}^{m-1} \hat{\tau}_{N_{k} \rightarrow N_{k+1}}(\mathbf{\Omega^{i}})
$$
In the CF-base approach, the treatment effects were always estimated using the the lowest treatment rate $N_1$. Therefore, the predicted treatment effects already represent the change in yields from the yield at $N_1$:
$$
\Delta Y_{N_1 \rightarrow N_m}(\mathbf{\Omega^{i}}) = \hat{\tau}_{N_{1} \rightarrow N_{m}}(\mathbf{\Omega^{i}})
$$

Once the treatment effects from the base were obtained, site-specific EONRs were identified by finding the N rate that leads to the highest profit. Yield levels were not predicted at any point in the CF-based approaches.  -->

RF, BRF, and CF from the `grf` package have several tunable hyperparameters (e.g., the minimum node size in each tree, the number of covariates used for node splitting, and parameters involving honest tree-building process), and the optimal values for these parameters are selected by cross-validation. In addition to these tuning parameters, we needed to set the number of trees grown in a forest (i.e., *num.trees*). Individual trees in a forest were built with randomly subsampled observations, leading to a different prediction in every forest even when the same dataset was used. To reduce the variance of predictions, in other words, to stabilize the prediction accuracy, we needed to assign *num.trees* a high value, $4000$.

### Model Evaluation

The accuracy of EONR estimation was judged based RMSE ($kg/ha$)of EONR estimation against the true EONR at the subplot level.
In addition, using the EONR estimates, we also calculated profit-deficit ($\$/ha$) (i.e., $\hat{\pi}_{def}$) relative to the true maximum profit at the subplot level. The maximized profit is the profit under the true yield response functions evaluated at $N_{opt}^{i}$. For RF, BRF, and CNN, the accuracy of yield prediction was judged based on the RMSE ($kg/ha$) of the yield prediction against the true yields at the subplot level. 

# Results and Discussions

## EONR Estimation

Table \@ref(tab:table-optN-subplot-wide) shows the mean RMSE of the EONR estimation and $\hat{\pi}_{def}$ over the $1000$ simulations; it makes immediately clear that CF-base considerably outperformed the other ML methods, and that the profits based on CF-base's EONR estimates were the closest to the true maximum profits. BRF performed considerably better predicting EONR than did RF.

<br>

```{r table-optN-subplot-wide, tab.cap = "Mean RMSE of EONR Estimation and Profit-deficit by ML Methods and Modeling Scenarios"}
report_table_optN
# knit_print(report_table_optN)
```

<br>

Interestingly, CNN completely failed in its estimations of site-specific EONRs. This happened because the site-specific yield response functions identified by CNN were linear, and all with the same slope. Therefore, CNN failed to capture a declining marginal product of N. The constant marginal product caused the estimated EONR to take on either the lowest or highest experimental N application rate. To examine whether this problem is product solely of the specific choice of CNN architecture, we also tested another CNN model, which was analogous to CNN-ST proposed by @barbosa2020modeling. 
This architecture also estimated that yield and N rates were perfectly linearly related, and also estimated site-specific EONR poorly. Note that @barbosa2020modeling just compared models through the lens of yield prediction but did not use the estimated models to derive EONRs. In some cases, CNN predicted yield well; but in all cases it predicting EONR poorly.

Figure \@ref(fig:dist-optN) and Figure \@ref(fig:dist-piLoss) show the distributions of the one thousand RMSEs of the EONR estimations and $\hat{\pi}_{def}$ by ML methods and modeling scenarios, respectively. The center of distribution mass of the CF-base's RMSE values and $\hat{\pi}_{def}$ are to the left of the centers of the distribution masses of the other methods' RMSE values, showing that CF-base more accurately and consistently estimated EONR across all the modeling scenarios. 
Interestingly, RF seems particularly vulnerable to the inclusion of more variables, with RMSE ($\hat{\pi}_{def}$) increasing from `r table_optN_prep[Model=="aby",rmse_optN_RF]` (`r table_optN_prep[Model=="aby", pi_loss_RF]`) in the "aby" scenario to `r table_optN_prep[Model=="aabbyytt", rmse_optN_RF]` (`r table_optN_prep[Model=="aabbyytt", pi_loss_RF]`) in the "aabbyytt" scenario. CF-base was more robust to the inclusion of additional variables. Overall, the simulations present CF-base as the clear winner in estimating EONR. 

```{r dist-optN, fig.width=6, fig.height=7, fig.cap = "Distributions of RMSE of EONR Estimation over Simulations"}
plot_dis_optN
```

```{r dist-piLoss, fig.width=6, fig.height=7, fig.cap = "Distributions of Profit Deficit over Simulations"}
piLoss_density
```

<br>

Figure \@ref(fig:plot-tre) illustrates the underlying cause of CF-base's superior EONR predictions. It plots the estimated treatment effects against true treatment effects by treatment types and ML methods (RF, BRF, and CF-base) under the "aabbyytt" scenario in one of the $1000$ simulations rounds. The figure shows that the estimated treatment effects did not exhibit significant bias, with the points clustered around the red 1-to-1 line. However, they differ substantially in the accuracy of their treatment effect estimations. Points are clustered much more tightly about the 1-to-1 line much for CF-base than RF and BRF. That is, CF-base estimates treatment effects much more efficiently than do the RF and BRF methods, which focus on yield prediction rather than treatment effect estimation.

```{r plot-tre, fig.width=7, fig.height=5, fig.cap = "True Treatment Effects vs Estimated Treatment Effects (Scenario: aabbyytt)"}
figure_te
```

`r ftext('NOTE: The red line in the figures denotes the 1-to-1 line to show the ideal relationship between true and estimated treatment effects.', fp_text(font.size = 9))`


## Yield Prediction and EONR Estimation
For RF, BRF and CNN, Figure \@ref(fig:plot-y-optN) plots the RMSE values of EONR estimation against the RMSE values of yield prediction, and the red line shows the best-fit line describing the relationship between them. 
For all the models the regression line was almost flat, showing little if any correlation between the two measures. In other words, the quality of a model's yield predictions provides little if any information about the quality of its EONR predictions. 

```{r plot-y-optN, fig.width=7, fig.height=5, fig.cap = "The Relationship in the Performance between EONR Estimation and Yield Prediction by ML Methods and Modeling Scenarios"}
fig_y_optN
```

`r ftext('NOTE: The red line in the figures denotes the best-fit line to explain the relationship between the RMSEs of EONR prediction and yield prediction.', fp_text(font.size = 9))`

<br>

Table \@ref(tab:table-y-subplot-wide) shows the mean RMSE of yield prediction over the $1000$ simulations. Since CF-base does not predict yield, the table only reports the results from RF, BRF and CNN. Compared to the result of EONR estimation, RF performed as well as BRF in the simple modeling scenarios of "aby" and "abytt." This fact along with the poor performance of RF in predicting EONR show that strong predictive power of yield levels does not imply accurate prediction of EONR. Further, RF shows vulnerability to the inclusion of many correlated variables, as is displayed for EONR prediction as well. While CNN performs worse than RF and BRF in "aby" and "abytt," it performs better than RF in more complicated modeling scenarios, showing robustness, at least in yield prediction, to inclusion of many correlated variables. Of course, while on average in the "aabbyy" and "aabbyytt" scenarios CNN predicted yields better than RF did, CNN's EONR predictions were worse than RF's, which further backs our claim that a good yield prediction capability does not imply good EONR prediction capability.

<br>

```{r table-y-subplot-wide, tab.cap = "Mean RMSE of Yield Prediction by ML Methods and Modeling Scenarios"}
report_table_y
```

<br>

All previous research has followed a two-step procedure to estimate site-specific EONRs. The first step is to select the model that predicts yield most accurately. The following step is to use that model to predict EONR.
Table \@ref(tab:count-table) shows that following this process led to the choice of the best (as measured by profit) EONR prediction model in fewer than $30\%$ of the "aby" and "abytt" simulation rounds, $40\%$ of the "aabbyy" simulation rounds, and $50\%$ of the "aabbyytt" simulation rounds examined here. For example, the table shows that, in the "aby" scenario, RF attained the lowest RMSE for yield prediction in `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` of $1000$ iterations, and attained the lowest $\hat{\pi}_{def}$ in `r summary_res_CNN_RF_BRF[Model=="aby", count_RF]` of those `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` iterations. That is, in `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]-summary_res_CNN_RF_BRF[Model=="aby", count_RF]` out of `r summary_res_CNN_RF_BRF[Model=="aby", count_y_RF]` rounds, the RF models best at yield prediction did not provide EONR estimates that led to high profits. Similarly, in all cases, CNN method never provided both the best yield prediction and the best EONR estimation simultaneously. In the rounds in which BRF predicted yield best, then the two-step process worked well. For example, Table \@ref(tab:count-table) shows that in the `r summary_res_CNN_RF_BRF[Model=="aby", count_y_BRF]` "aby" simulation rounds in which BRF predicted yields best, it offered the best EONR recommendations `r summary_res_CNN_RF_BRF[Model=="aby", count_BRF]` times. But, BRF predicted yields best in fewer than $30\%$ of the rounds, implying that the two-step procedure failed more than $70\%$. 

<br>

```{r count-table, tab.cap = "Relationship between the EONR Prediction Performances (as measured by profit) and the Yield Prediction Performances for Prediction-oriented ML Methods"}
report_summary_res_CNN_RF_BRF
```

<br>

Virtually all the previous studies have used yield prediction accuracy to rank and select models. This is understandable, since whereas yield can be "ground-truthed" the true causal impact of a treatment cannot be determined from real-world data, making it impossible to cross-validate EONR. 
However, the simulation results reported here show clearly that using a modelâ€™s yield prediction accuracy as a model selection criterion is not well justified if the ultimate objective is accurate estimation of site-specific EONRs. 

# Conclusion

ML methods are appealing tools that can potentially improve site-specific input rate management by capturing heterogeneous treatment effects introduced by complex non-linear and multidimensional interactions of soil and field characteristics. Many kinds of prediction-oriented ML methods have been used for this purpose. We have introduced the use of CF, a relatively new method, which, unlike prediction-oriented ML methods, focuses on the identification of heterogeneous causal effects of treatment.

We examined the use of CF-base for site-specific input management recommendations. Using Monte Carlo simulations under various modeling scenarios, we compared the CF estimations of site-specific EONR to those of the prediction-oriented ML methods RF, BRF, and CNN. CF-base consistently outperformed the other methods across all the modeling scenarios in terms of EOIR prediction and profit generation. We also showed that the modelâ€™s yield prediction accuracy was uncorrelated with its EONR prediction accuracy, and so yield prediction accuracy should not be used as a model selection criterion if the ultimate goal of the experiment is to identify EOIR map.

Despite the relatively simple nature of the simulations, results reported provide intriguing evidence of potential advantages of CF over other ML methods when the purpose of the research is to increase the economic efficiency of input management. Of course, the reported research did not model all situations, and further research is needed. First, a drawback of the CF method is that because it does not estimate a continuous yield response function, it can only compare the economic outcomes of a limited set of experimental N rates included in the field trial that provides the data. This raises important questions about trial design. How many distinct experimental input application rates should be included? All the trial designs examined here were based on five N rates. Having examined models with additional rates would have increased the number of possible N rates from which the EONR were selected, but reduced treatment pair replications and so the estimation accuracy.

Second, the size of the field used in the OFPE can affect the relative performances of the competing methods. CF requires honest sampling for its unbiasedness property. Honest sampling comes at the cost of losing prediction accuracy of treatment effects because fewer samples are used to estimate treatment effects within leaves [@athey2016recursive]. Therefore, if the ML analyses are conducted with OFPE data from a small field, CF may not outperform other ML methods

Third, another interesting subject for future research is the potential of combining the ML methods with post-estimation spatial smoothing of the estimated EONR. It is a well known fact that soil/field characteristics are spatially correlated [@f2007methods;@goovaerts1999geostatistics]; this spatial correlation is likely to cause spatial correlation in EONRs, which would suggest that post-estimation spatial smoothing of EONRs may further improve the accuracy of EONR estimation.

Finally, a natural and fruitful extension of the reported research would be to test CF and other ML methods in a dynamic setting where multiple years of experiments are conducted, allowing weather events into the analysis as explanatory variables. Crop simulation models (e.g., APSIM, DSSAT) could be used in place of the Mitscherlich-Baule production function used here to model the underlying yield response function, which could generate more realistic data, using actual soil/field characteristics and weather instead of abstract parameters in the analysis, and so better include the dynamic nature of cropping systems in the study of N management [@archontoulis2020predicting;@puntel2016modeling;@puntel2018systems].

# Acknowledgement

This research was supported by a USDA-NIFA-AFRI Food Security Program Coordinated Agricultural Project, titled "Using Precision Technology in On-farm Field Trials to Enable Data-Intensive Fertilizer Management," (Accession Number 2016-68004-24769), and also by the a USDA-NRCS Conservation Innovation Grant from the On-farm Trials Program, titled "Improving the Economic and Ecological Sustainability of US Crop Production through On-Farm Precision Experimentation" (Award Number NR213A7500013G021). 

\newpage


# References

<div id="refs"></div>












